 The bash script our group made automates the monitoring of a system by capturing system activity using the sysdig tool every 30 minutes. Each session stops when the data file reaches about 20 MB or after 4 hours of total runtime. When the bash script is done logging we of course need to go over the logs and make sure everything is okay and that no one has tried anything to breach our resources (website, security, etc). The script checks if each generated file exceeds a size limit of 20MB and, if so, runs a specific program designed to print the scaps for the allotted memory during that time period so we can check them. This can be useful for system monitoring, security analysis, and troubleshooting. 

The script helps manage data capture efficiently but requires careful consideration regarding storage, privacy, and the potential impact on system performance. Another layer to add to logging is the infamous trouble with obtaining multiple scaps. When testing the bash script it came to my attention that you can only have one of the same scap, regardless of how many times the bash script runs. This means that if you were to manually delete a scap file and leave it in the trash all that data is still being accounted for, which in turn makes it so you cannot make multiple copies of a pcap if you were to restart the bash script/service. Now the nice part about all of this is that we can simply just delete it once it is done and the bash script can go about doing its job. Looking back at it all of this makes more sense in term of making sure scaps arent something you can take lightly because the task they have is important and very useful. In conclusion, logging has its ups and downs but the pros outweigh the cons in a majority of ways   
